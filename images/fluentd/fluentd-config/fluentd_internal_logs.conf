
<filter fluent.**>
  @type record_transformer
  @id filter_record_transformer_fluent_all
  renew_record true
  enable_ruby true
  <record>
    timestamp ${time.strftime('%Y-%m-%d %H:%M:%S.%6N')}
    severity ${tag_parts.last}
    message ${record.to_json}
  </record>
</filter>

#logs internal Fluentd logs into dedicated index

<match fluent.**>
    @type elasticsearch
    @id match_es_fluent_all

    #general settings:
    host elastic
    port 9200
    flush_interval 1s

    #below index name is not used:
    index_name fluentd_logs_fallback

    #index data into hourly rotated index:
    type_name logs
    logstash_format true
    logstash_prefix fluentd_logs_001
    logstash_prefix_separator _
    logstash_dateformat %Y%m%d

    #take time from record itself but don't index @timestamp field:
    time_key timestamp
    time_key_format "%Y-%m-%d %H:%M:%S.%N"
    time_precision 6
    include_timestamp false
    time_key_exclude_timestamp true

    #load specific index template:
    template_name template_fluentd_logs_001
    template_file /fluentd/etc/templates/template_fluentd_logs.json
    max_retry_putting_template 100
</match>
