


<source>
  @type monitor_agent
  tag monitor.metrics
  bind 0.0.0.0
  port 24220
  emit_interval 2
  include_config false
  include_retry false
</source>

<filter monitor.metrics>
  @type record_transformer
  renew_record true
  keep_keys ["plugin_id", "plugin_category", "type", "output_plugin", "buffer_queue_length", "buffer_total_queued_size", "retry_count"]
  enable_ruby true
  <record>
    timestamp ${time.strftime('%Y-%m-%d %H:%M:%S.%6N')}
    debug ${record.to_json}
  </record>
</filter>

#logs internal Fluentd metrics into dedicated index
<match monitor.metrics>
    @type elasticsearch

    #general settings:
    host elastic
    port 9200
    flush_interval 1s

    #below index name is not used:
    index_name fluentd_metrics_fallback

    #index data into hourly rotated index:
    type_name docs
    logstash_format true
    logstash_prefix fluentd_metrics_001
    logstash_prefix_separator _
    logstash_dateformat %Y%m%d

    #take time from record itself but don't index @timestamp field:
    time_key timestamp
    time_key_format "%Y-%m-%d %H:%M:%S.%N"
    time_precision 6
    include_timestamp false
    time_key_exclude_timestamp true

    #load specific index template:
    template_name template_fluentd_metrics_001
    template_file /fluentd/etc/templates/template_fluentd_metrics.json
    max_retry_putting_template 100
</match>
